{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import math\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import facenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir  = \"data/dataset/train\"\n",
    "test_dir  = \"data/dataset/test\"\n",
    "model_dir = \"data/20180402-114759/\"\n",
    "\n",
    "batch_size = 5\n",
    "image_size = 160\n",
    "\n",
    "LOG_DIR = 'tboard'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed(g, sess, data_dir):\n",
    "    dataset = facenet.get_dataset(data_dir)\n",
    "    paths, labels = facenet.get_image_paths_and_labels(dataset)\n",
    "    # Restoe model\n",
    "    facenet.load_model(model_dir)\n",
    "    # Get input and output tensors\n",
    "    images_placeholder = g.get_tensor_by_name(\"input:0\")\n",
    "    embeddings = g.get_tensor_by_name(\"embeddings:0\")\n",
    "    phase_train_placeholder = g.get_tensor_by_name(\"phase_train:0\")\n",
    "    embedding_size = embeddings.get_shape()[1]\n",
    "\n",
    "    # Run forward pass to calculate embeddings\n",
    "    nrof_images = len(paths)\n",
    "    nrof_batches_per_epoch = int(math.ceil(1.0*nrof_images / batch_size))\n",
    "    emb_array = np.zeros((nrof_images, embedding_size))\n",
    "\n",
    "    for i in range(nrof_batches_per_epoch):\n",
    "        start_index = i*batch_size\n",
    "        end_index = min((i+1)*batch_size, nrof_images)\n",
    "\n",
    "        paths_batch = paths[start_index:end_index]\n",
    "        images = facenet.load_data(paths_batch, False, False, image_size)\n",
    "        feed_dict = { images_placeholder:images, phase_train_placeholder:False }\n",
    "        emb_array[start_index:end_index,:] = sess.run(embeddings, feed_dict=feed_dict)\n",
    "    return emb_array, labels, dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = tf.Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with g.as_default():\n",
    "    with tf.Session() as sess:\n",
    "        emb_array, labels, trainset = embed(g, sess, train_dir)\n",
    "        test_emb_array, test_labels, testset = embed(g, sess, train_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with g.as_default():\n",
    "    with tf.Session() as sess:\n",
    "        test_emb_array, test_labels, testset = embed(g, sess, train_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Face Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_size = emb_array.shape[1]\n",
    "num_classes  = max(labels)+1\n",
    "hidden1_size = 256\n",
    "\n",
    "# Hyperparamters\n",
    "learning_rate = 0.001\n",
    "max_steps = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "    return tf.Variable(tf.truncated_normal(shape, stddev=0.1))\n",
    "\n",
    "def bias_variable(shape):\n",
    "    return tf.Variable(tf.constant(0.1, shape=shape))\n",
    "\n",
    "def variable_summaries(var):\n",
    "    with tf.name_scope('summaries'):\n",
    "        mean = tf.reduce_mean(var)\n",
    "        tf.summary.scalar('mean', mean)\n",
    "        with tf.name_scope('stddev'):\n",
    "            stddev = tf.sqrt(tf.reduce_mean(tf.square(var - mean)))\n",
    "        tf.summary.scalar('stddev', stddev)\n",
    "        tf.summary.scalar('max', tf.reduce_max(var))\n",
    "        tf.summary.scalar('min', tf.reduce_min(var))\n",
    "        tf.summary.histogram('histogram', var)\n",
    "\n",
    "def nn_layer(input_tensor, input_dim, output_dim, layer_name, activation=tf.nn.relu):\n",
    "    # Adding a name scope ensures logical grouping of the layers in the graph.\n",
    "    with tf.name_scope(layer_name):\n",
    "        # This Variable will hold the state of the weights for the layer\n",
    "        with tf.name_scope('weights'):\n",
    "            weights = weight_variable([input_dim, output_dim])\n",
    "        with tf.name_scope('biases'):\n",
    "            biases = bias_variable([output_dim])\n",
    "        with tf.name_scope('Wx_plus_b'):\n",
    "            preactivate = tf.matmul(input_tensor, weights) + biases\n",
    "\n",
    "        activations = activation(preactivate, name='activation')\n",
    "        tf.summary.histogram('activations', activations)\n",
    "        return activations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input placeholders\n",
    "with tf.name_scope('input'):\n",
    "    x = tf.placeholder(tf.float32, [None, emb_size], name='x-input')\n",
    "    y_true = tf.placeholder(tf.int64, [None], name='y-input')\n",
    "\n",
    "hidden1 = nn_layer(x, emb_size, hidden1_size, 'layer1')\n",
    "y = nn_layer(hidden1, hidden1_size, num_classes, 'layer2', activation=tf.identity)\n",
    "\n",
    "with tf.name_scope('cross_entropy'):\n",
    "    with tf.name_scope('total'):\n",
    "        cross_entropy = tf.losses.sparse_softmax_cross_entropy(\n",
    "            labels=y_true, logits=y)\n",
    "tf.summary.scalar('cross_entropy', cross_entropy)\n",
    "\n",
    "with tf.name_scope('train'):\n",
    "    train_step = tf.train.AdamOptimizer(learning_rate).minimize(\n",
    "        cross_entropy)\n",
    "\n",
    "with tf.name_scope('accuracy'):\n",
    "    with tf.name_scope('correct_prediction'):\n",
    "        correct_prediction = tf.equal(tf.argmax(y, 1), y_true)\n",
    "    with tf.name_scope('accuracy'):\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "tf.summary.scalar('accuracy', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Face Recognizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feed_dict(train):\n",
    "    if train: \n",
    "        xs, ys = emb_array, labels\n",
    "    else:\n",
    "        xs, ys = test_emb_array, test_labels\n",
    "    return {x: xs, y_true: ys}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    # Merge all the summaries and write them out\n",
    "    merged = tf.summary.merge_all()\n",
    "    train_writer = tf.summary.FileWriter(LOG_DIR + '/train', sess.graph)\n",
    "    test_writer = tf.summary.FileWriter(LOG_DIR + '/test')\n",
    "    tf.global_variables_initializer().run()\n",
    "\n",
    "    for i in range(max_steps):\n",
    "        if i % 10 == 0:  # Record summaries and test-set accuracy\n",
    "            summary, acc = sess.run([merged, accuracy], feed_dict=feed_dict(False))\n",
    "            test_writer.add_summary(summary, i)\n",
    "            print('Accuracy at step %s: %s' % (i, acc))\n",
    "        else:  # Record train set summaries, and train\n",
    "            if i % 50 == 49:  # Record execution stats\n",
    "                #run_options = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE)\n",
    "                #run_metadata = tf.RunMetadata()\n",
    "                summary, _ = sess.run([merged, train_step],\n",
    "                                      feed_dict=feed_dict(True))#,\n",
    "                                      #options=run_options,\n",
    "                                      #run_metadata=run_metadata)\n",
    "                #train_writer.add_run_metadata(run_metadata, 'step%03d' % i)\n",
    "                train_writer.add_summary(summary, i)\n",
    "                print('Adding run metadata for', i)\n",
    "            else:  # Record a summary\n",
    "                summary, _ = sess.run([merged, train_step], feed_dict=feed_dict(True))\n",
    "                train_writer.add_summary(summary, i)\n",
    "                \n",
    "train_writer.close()\n",
    "test_writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_tutorial",
   "language": "python",
   "name": "tf_tutorial"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
